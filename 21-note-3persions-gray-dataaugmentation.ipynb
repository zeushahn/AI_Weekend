{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11222618,"sourceType":"datasetVersion","datasetId":7008803}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Data Augmentation으로 비정형 데이터의 증강","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport glob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T01:15:38.982725Z","iopub.execute_input":"2025-04-05T01:15:38.983040Z","iopub.status.idle":"2025-04-05T01:15:38.986697Z","shell.execute_reply.started":"2025-04-05T01:15:38.983010Z","shell.execute_reply":"2025-04-05T01:15:38.985882Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Folder Name\ndirNames = ['Aiden', 'Andrew', 'Cathy']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T01:16:10.070261Z","iopub.execute_input":"2025-04-05T01:16:10.070674Z","iopub.status.idle":"2025-04-05T01:16:10.075123Z","shell.execute_reply.started":"2025-04-05T01:16:10.070623Z","shell.execute_reply":"2025-04-05T01:16:10.074175Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# 작업 폴더 생성\nimport os\nos.mkdir(\"./Face\")\nos.mkdir(\"./Face/Data\")\nfor name in dirNames:\n    os.mkdir(f\"./Face/Data/{name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T01:18:45.399662Z","iopub.execute_input":"2025-04-05T01:18:45.399945Z","iopub.status.idle":"2025-04-05T01:18:45.404106Z","shell.execute_reply.started":"2025-04-05T01:18:45.399924Z","shell.execute_reply":"2025-04-05T01:18:45.403385Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Ratation과 Flip으로 데이터 증강(원본데이터 + Rotation Data + Flip Data)\n\nfor name in dirNames:\n    for file in sorted(glob.glob(f\"/kaggle/input/data-face/{name}/image*.jpg\")):\n        imgData = Image.open(file)\n        # 원본 데이터 저장\n        imgData.save(f\"./Face/Data/{name}/{file.split('/')[-1]}\") # 원본데이터는 원래아름으로 정의 \n        counter = 0\n        for angle in range(-15, 15, 1):\n            counter+=1\n            imgData2 = imgData.rotate(angle)\n            imgData2.save(f\"./Face/Data/{name}/rotation_{counter:03d}.png\")\n\n            imgData3 = imgData2.transpose(Image.FLIP_LEFT_RIGHT)\n            imgData3.save(f\"./Face/Data/{name}/flip_{counter:03d}.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T01:37:43.499782Z","iopub.execute_input":"2025-04-05T01:37:43.500109Z","iopub.status.idle":"2025-04-05T01:39:19.936513Z","shell.execute_reply.started":"2025-04-05T01:37:43.500050Z","shell.execute_reply":"2025-04-05T01:39:19.935824Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Ex : file name 정의\n\nstr = \"/kaggle/input/data-face/Aiden/image_0000.jpg\"\nstr.split(\"/\")[-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T01:29:41.214151Z","iopub.execute_input":"2025-04-05T01:29:41.214432Z","iopub.status.idle":"2025-04-05T01:29:41.218998Z","shell.execute_reply.started":"2025-04-05T01:29:41.214410Z","shell.execute_reply":"2025-04-05T01:29:41.218381Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'image_0000.jpg'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3명의 얼굴을 학습하여 인식하기","metadata":{}},{"cell_type":"code","source":"# Module\nimport numpy as np\nfrom PIL import Image\nimport glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n### 전체 사진중 최대 해상도 찾기","metadata":{}},{"cell_type":"code","source":"dirNames = ['Aiden', 'Andrew', 'Cathy']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"widthRatio = []\nheightRatio = []\n\nfor name in dirNames:\n    for file in sorted(glob.glob(f\"/kaggle/input/data-face/{name}/image*.jpg\")):\n        img = np.array(Image.open(file))\n        widthRatio.append(img.shape[1])\n        heightRatio.append(img.shape[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('너비 최대 해상도 :', np.max(widthRatio))\nprint('높이 최대 해상도 :', np.max(heightRatio))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> 해상도의 크기를 400 X 300","metadata":{}},{"cell_type":"markdown","source":"---\n### 전체 사진을 흑백으로 변경하고 검은색 배경(400X300)의 중앙에 일치 시켜 저장하기 ","metadata":{}},{"cell_type":"code","source":"# 작업 폴더 생성 \nimport os\nos.mkdir(\"./Face\")\nos.mkdir(\"./Face/Gray\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 이름별 directory 생성\n\nfor name in dirNames:\n    os.mkdir(f\"./Face/Gray/{name}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for name in dirNames:\n    fileCount = 0\n    for file in sorted(glob.glob(f\"/kaggle/input/data-face/{name}/image*.jpg\")):\n        img = Image.open(file)\n        imgResize = img.convert('L')\n        imgArray = np.array(imgResize)\n\n        imgDummy = np.zeros(400*300).reshape(400, 300)\n\n        rowNum = (400 - imgArray.shape[0]) / 2\n        colNum = (300 - imgArray.shape[1]) / 2\n\n        k = 0\n        for i in list(range(int(rowNum), int(rowNum) + imgArray.shape[0])):\n            l = 0\n            for j in list(range(int(colNum), int(colNum) + imgArray.shape[1])):\n                imgDummy[i,j] = imgArray[k,l]\n                l +=1\n            k +=1\n        img2 = Image.fromarray(imgDummy.astype('uint8'), 'L')\n        img2.save(f\"/kaggle/working/Face/Gray/{name}/image_{fileCount:04d}.jpg\",\"JPEG\")\n        fileCount +=1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 사진들을 numpy배열을 이용하여 Training Data 만들기","metadata":{}},{"cell_type":"code","source":"number_of_data = 18 * len(dirNames)\nimg_width_size = 300\nimg_height_size = 400","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = np.zeros(number_of_data * img_width_size * img_height_size).reshape(number_of_data, img_height_size, img_width_size)\ni = 0\n\nfor name in dirNames:\n    for file in sorted(glob.glob(f\"/kaggle/working/Face/Gray/{name}/*.jpg\")):\n        img = np.array(Image.open(file))\n        train_data[i,:,:] = img\n        i+=1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 이미지 확인","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(train_data[20], cmap='gray')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 여러개의 이미지를 같이 보기\nplt.figure(figsize=(20, 20))\norderNo = list(range(0, len(dirNames)*18, 18))\n\nfor i in list(range(1, len(dirNames)+1)):\n    plt.subplot(1, len(dirNames), i)\n    plt.imshow(train_data[orderNo[i-1]].reshape(400, 300), cmap='gray')\n    plt.title(dirNames[i-1])\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Target Data만들기","metadata":{}},{"cell_type":"code","source":"# a = [0 for _ in range(18)]\n# b = [1 for _ in range(18)]\n# c = [2 for _ in range(18)]\n# target_data = a + b + c\n\ntarget_data = [num for num in range(3) for _ in range(18)]\nprint(target_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n### Data들을 Tensor로 변환","metadata":{}},{"cell_type":"code","source":"import torch\n\ntrain_input = torch.tensor(train_data)\ntrain_target = torch.tensor(target_data)\n\nprint(train_input.data.shape)\nprint(train_target.data.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### train data를 훈련데이터와 검증데이터로 나누기 (정규화, 채널 추가)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_input = train_input.data.unsqueeze(1).float() / 255.0 # 채널 차원 및 정규화\ntrain_input, val_input, train_target, val_target = train_test_split(\n                                                        train_input,\n                                                        train_target,\n                                                        test_size=0.2,\n                                                        random_state=42\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dimension 확인\nprint(train_input.shape, train_target.shape)\nprint(val_input.shape, val_target.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"--- \n### CNN 신경망 만들기","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset 및 DataLoader 생성\nbatch_size = 32 # mini batch\ntrain_dataset = TensorDataset(train_input, train_target)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\nval_dataset = TensorDataset(val_input, val_target)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 모델 정의","metadata":{}},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(64 * 100 * 75, 128) # 64, (400/4), (300/4)\n        self.relu3 = nn.ReLU()\n        # self.dropout = nn.Dropout(0.9)\n        self.fc2 = nn.Linear(128, 3)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.pool1(x)\n\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.pool2(x)\n\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu3(x)\n        # x = self.dropout(x)\n        x = self.fc2(x)\n        return x ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모델, 손실함수, 옵티마이저 초기화\nmodel = CNNModel()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 학습 함수\ndef train(model, train_loader, criterion, optimizer, device):\n    model.train()\n    for inputs, targets in train_loader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad() # 이전 반복에서 계산된 그레디언트를 초기화 \n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward() # 손실에 대한 그레디언트를 계산하고 역전파 \n        optimizer.step() \n    return loss.item()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 평가함수\ndef evaluate(model, val_loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in val_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n    return total_loss / len(val_loader), correct / total","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 훈련 반복\n\ntrain_loss_scores = [] # train score list\nval_loss_scores = [] # test score list\n\nnum_epochs = 50\n\nfor epoch in range(num_epochs):\n    train_loss = train(model, train_loader, criterion, optimizer, device)\n    val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n    train_loss_scores.append(train_loss)\n    val_loss_scores.append(val_loss)\n    print(f'Epoch : [{epoch+1} / {num_epochs}], Train Loss : {train_loss:.4f}, Val Loss : {val_loss:.4f}, Val Accuracy : {val_accuracy:.4f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 훈련 데이터로 평가\ntrain_loss, train_accuracy = evaluate(model, train_loader, criterion, device)\nprint(f'Training Loss : {train_loss:.4f}, Training Accuracy : {train_accuracy:.4f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 검증 데이터로 평가\nval_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\nprint(f'Validation Loss : {val_loss:.4f}, Validation Accuracy : {val_accuracy:.4f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 시각화 해보기\n\nplt.plot(train_loss_scores)\nplt.plot(val_loss_scores)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['train','test'])\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n### 이미지 불러와서 예측해 보기","metadata":{}},{"cell_type":"code","source":"# Image\nimg = Image.open(\"/kaggle/working/Face/Gray/Cathy/image_0000.jpg\")\nimg","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# image를 numpy 배열로 변환\nimg = np.array(img)\nimg.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# numpy배열을 torch 변환\nimg = torch.from_numpy(img)\nimg.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 정규화 시키기\nimg = img.unsqueeze(0).float() / 255.0\nimg.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Class들의 이름 정의\nclasses = ['Aiden', 'Andrew', 'Cathy']\nclasses","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 예측 함수\ndef predict_single_image(model, image, device, classes):\n    model.eval()\n    with torch.no_grad():\n        image = image.to(device)\n        output = model(image.unsqueeze(0))\n        _, predicted = torch.max(output, 1)\n        predicted_class = classes[predicted.item()]\n    return predicted_class","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 예측 수행\npredict_single_image(model, img, device, classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n### 학습한 모델 저장하기","metadata":{}},{"cell_type":"code","source":"# 전체 모델 저장\ntorch.save(model, './cnn_3_persons.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 전체 모델 불러오기\nmodel1 = torch.load(\"./cnn_3_persons.pth\", weights_only=False)\nmodel1.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_single_image(model1, img, device, classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}